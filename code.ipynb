{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7963428432552002\n"
     ]
    }
   ],
   "source": [
    "#Question 1a\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "wine = pd.read_csv('wine.txt', sep = '\\t')\n",
    "wine.head()\n",
    "\n",
    "# Extract predictors and response variable\n",
    "X = wine.drop(columns=[\"Quality\"])\n",
    "y = wine[\"Quality\"]\n",
    "\n",
    "# Initialize LOOCV\n",
    "loocv = LeaveOneOut()\n",
    "\n",
    "# Initialize an array to store the test MSE for each fold\n",
    "test_mse = []\n",
    "\n",
    "# Perform LOOCV\n",
    "for train_index, test_index in loocv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit a linear regression model on the training data\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate the test MSE for this fold\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    test_mse.append(mse)\n",
    "    \n",
    "# Compute the average test MSE across all folds\n",
    "average_test_mse_a = np.mean(test_mse)\n",
    "print(average_test_mse_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Subset Model (Predictors): ('Clarity', 'Oakiness')\n",
      "Test MSE of the Best Model: 4.706194265856787\n"
     ]
    }
   ],
   "source": [
    "#Question 1b\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "# Create a list of all predictor variables\n",
    "predictors = X.columns\n",
    "\n",
    "# Initialize variables to keep track of the best model and its performance\n",
    "best_model = None\n",
    "best_mse = float('inf')\n",
    "best_adj_r2 = -float('inf')\n",
    "\n",
    "# Perform best-subset selection\n",
    "for k in range(1, len(predictors) + 1):\n",
    "    for subset in combinations(predictors, k):\n",
    "        # Create a model using the current subset of predictors\n",
    "        subset_idx = [predictors.get_loc(p) for p in subset]\n",
    "        X_subset = X.iloc[:, subset_idx]\n",
    "        \n",
    "        # Initialize an array to store the test MSE for this subset\n",
    "        test_mse_subset = []\n",
    "        \n",
    "        # Perform LOOCV for the current subset of predictors\n",
    "        for train_index, test_index in loocv.split(X_subset):\n",
    "            X_train, X_test = X_subset.iloc[train_index], X_subset.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            # Fit a linear regression model on the training data\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions on the test data\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate the test MSE for this fold\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            test_mse_subset.append(mse)\n",
    "        \n",
    "        # Compute the average test MSE across all folds for this subset\n",
    "        avg_mse_subset = np.mean(test_mse_subset)\n",
    "        \n",
    "        # Calculate the adjusted R^2 for this subset\n",
    "        n = X_subset.shape[0]\n",
    "        p = len(subset)\n",
    "        adj_r2 = 1 - (1 - avg_mse_subset) * ((n - 1) / (n - p - 1))\n",
    "        \n",
    "        # Check if this model has a better adjusted R^2 and lower test MSE\n",
    "        if adj_r2 > best_adj_r2:\n",
    "            best_model = subset\n",
    "            best_adj_r2 = adj_r2\n",
    "            best_mse = avg_mse_subset\n",
    "\n",
    "# Now, fit the best model with all data\n",
    "best_model_idx = [predictors.get_loc(p) for p in best_model]\n",
    "X_best = X.iloc[:, best_model_idx]\n",
    "model = LinearRegression()\n",
    "model.fit(X_best, y)\n",
    "\n",
    "# Compute the test MSE of the best model using LOOCV\n",
    "test_mse_best_model = []\n",
    "\n",
    "for train_index, test_index in loocv.split(X_best):\n",
    "    X_train, X_test = X_best.iloc[train_index], X_best.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    test_mse_best_model.append(mse)\n",
    "\n",
    "# Compute the average test MSE for the best model\n",
    "average_test_mse_best_subset = np.mean(test_mse_best_model)\n",
    "\n",
    "# Print the best model and its test MSE\n",
    "print(\"Best Subset Model (Predictors):\", best_model)\n",
    "print(\"Test MSE of the Best Model:\", average_test_mse_best_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Forward Stepwise Model (Predictors): ['Clarity', 'Oakiness', 'Region', 'Body', 'Aroma', 'Flavor']\n",
      "Test MSE of the Best Model: 1.796342843255199\n"
     ]
    }
   ],
   "source": [
    "#Question 1c\n",
    "\n",
    "# Create a list of all predictor variables\n",
    "predictors = X.columns\n",
    "\n",
    "# Initialize an empty list to store the selected predictors\n",
    "selected_predictors = []\n",
    "\n",
    "# Initialize variables to keep track of the best model and its performance\n",
    "best_model = None\n",
    "best_mse = float('inf')\n",
    "best_adj_r2 = -float('inf')\n",
    "\n",
    "# Perform forward stepwise selection\n",
    "while len(selected_predictors) < len(predictors):\n",
    "    remaining_predictors = [p for p in predictors if p not in selected_predictors]\n",
    "    \n",
    "    # Initialize variables to keep track of the best predictor to add and its performance\n",
    "    best_predictor = None\n",
    "    best_mse_with_predictor = float('inf')\n",
    "    best_adj_r2_with_predictor = -float('inf')\n",
    "    \n",
    "    for predictor in remaining_predictors:\n",
    "        # Create a model using the current set of selected predictors and the predictor to be added\n",
    "        predictors_to_add = selected_predictors + [predictor]\n",
    "        X_subset = X[predictors_to_add]\n",
    "        \n",
    "        # Initialize an array to store the test MSE for this subset\n",
    "        test_mse_subset = []\n",
    "        \n",
    "        # Perform LOOCV for the current subset of predictors\n",
    "        for train_index, test_index in loocv.split(X_subset):\n",
    "            X_train, X_test = X_subset.iloc[train_index], X_subset.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            # Fit a linear regression model on the training data\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions on the test data\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate the test MSE for this fold\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            test_mse_subset.append(mse)\n",
    "        \n",
    "        # Compute the average test MSE across all folds for this subset\n",
    "        avg_mse_subset = np.mean(test_mse_subset)\n",
    "        \n",
    "        # Calculate the adjusted R^2 for this subset\n",
    "        n = X_subset.shape[0]\n",
    "        p = len(predictors_to_add)\n",
    "        adj_r2 = 1 - (1 - avg_mse_subset) * ((n - 1) / (n - p - 1))\n",
    "        \n",
    "        # Check if this predictor addition has a better adjusted R^2 and lower test MSE\n",
    "        if adj_r2 > best_adj_r2_with_predictor:\n",
    "            best_predictor = predictor\n",
    "            best_adj_r2_with_predictor = adj_r2\n",
    "            best_mse_with_predictor = avg_mse_subset\n",
    "    \n",
    "    # Add the best predictor to the selected predictors\n",
    "    selected_predictors.append(best_predictor)\n",
    "    \n",
    "    # Update the best model and its performance\n",
    "    if best_mse_with_predictor < best_mse:\n",
    "        best_model = selected_predictors.copy()\n",
    "        best_mse = best_mse_with_predictor\n",
    "        best_adj_r2 = best_adj_r2_with_predictor\n",
    "\n",
    "# Now, fit the best model with all data\n",
    "X_best = X[best_model]\n",
    "model = LinearRegression()\n",
    "model.fit(X_best, y)\n",
    "\n",
    "# Compute the test MSE of the best model using LOOCV\n",
    "test_mse_best_model = []\n",
    "\n",
    "for train_index, test_index in loocv.split(X_best):\n",
    "    X_train, X_test = X_best.iloc[train_index], X_best.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    test_mse_best_model.append(mse)\n",
    "\n",
    "# Compute the average test MSE for the best model\n",
    "average_test_mse_forward = np.mean(test_mse_best_model)\n",
    "\n",
    "# Print the best model and its test MSE\n",
    "print(\"Best Forward Stepwise Model (Predictors):\", best_model)\n",
    "print(\"Test MSE of the Best Model:\", average_test_mse_forward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\ann\\fall 2023\\stat 4360\\project 4\\code.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ann/fall%202023/stat%204360/project%204/code.ipynb#W5sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m y_train, y_test \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39miloc[train_index], y\u001b[39m.\u001b[39miloc[test_index]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ann/fall%202023/stat%204360/project%204/code.ipynb#W5sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# # Fit a linear regression model on the training data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ann/fall%202023/stat%204360/project%204/code.ipynb#W5sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# model = LinearRegression()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ann/fall%202023/stat%204360/project%204/code.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# model.fit(X_train, y_train)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ann/fall%202023/stat%204360/project%204/code.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ann/fall%202023/stat%204360/project%204/code.ipynb#W5sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Make predictions on the test data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/ann/fall%202023/stat%204360/project%204/code.ipynb#W5sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ann/fall%202023/stat%204360/project%204/code.ipynb#W5sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m mse \u001b[39m=\u001b[39m mean_squared_error(y_test, y_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/ann/fall%202023/stat%204360/project%204/code.ipynb#W5sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m test_mse_subset\u001b[39m.\u001b[39mappend(mse)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:386\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    373\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[39m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:370\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    367\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    369\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X, accept_sparse\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m], reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 370\u001b[0m \u001b[39mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LinearRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "# Question 1d\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Extract predictors and response variable\n",
    "X = wine.drop(columns=[\"Quality\"])\n",
    "y = wine[\"Quality\"]\n",
    "\n",
    "# Initialize LOOCV\n",
    "loocv = LeaveOneOut()\n",
    "\n",
    "# Create a list of all predictor variables\n",
    "predictors = X.columns\n",
    "\n",
    "# Initialize the list of selected predictors with all predictors\n",
    "selected_predictors = predictors.copy()\n",
    "\n",
    "# Initialize variables to keep track of the best model and its performance\n",
    "best_model = selected_predictors\n",
    "best_mse = float('inf')\n",
    "\n",
    "# Perform backward stepwise selection\n",
    "while len(selected_predictors) > 0:\n",
    "    # Initialize variables to keep track of the best predictor to remove and its performance\n",
    "    worst_predictor = None\n",
    "    worst_mse_without_predictor = float('inf')\n",
    "    \n",
    "    for predictor in selected_predictors:\n",
    "        # Create a model using the current set of selected predictors without the predictor to be removed\n",
    "        predictors_to_remove = selected_predictors.copy()\n",
    "        predictors_to_remove.drop(predictor)\n",
    "        X_subset = X[predictors_to_remove]\n",
    "        \n",
    "        # Initialize an array to store the test MSE for this subset\n",
    "        test_mse_subset = []\n",
    "        \n",
    "        # Perform LOOCV for the current subset of predictors\n",
    "        for train_index, test_index in loocv.split(X_subset):\n",
    "            X_train, X_test = X_subset.iloc[train_index], X_subset.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            # Fit a linear regression model on the training data\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions on the test data\n",
    "            y_pred = model.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            test_mse_subset.append(mse)\n",
    "        \n",
    "        # Compute the average test MSE across all folds for this subset\n",
    "        avg_mse_subset = np.mean(test_mse_subset)\n",
    "        \n",
    "        # Calculate the adjusted R^2 for this subset\n",
    "        n = X_subset.shape[0]\n",
    "        p = len(predictors_to_remove)\n",
    "        adj_r2 = 1 - (1 - avg_mse_subset) * ((n - 1) / (n - p - 1))\n",
    "        \n",
    "        # Check if removing this predictor has a better adjusted R^2 and lower test MSE\n",
    "        if avg_mse_subset < worst_mse_without_predictor:\n",
    "            worst_predictor = predictor\n",
    "            worst_mse_without_predictor = avg_mse_subset\n",
    "    \n",
    "    # Remove the worst predictor from the selected predictors\n",
    "    selected_predictors.drop(worst_predictor)\n",
    "    \n",
    "    # Update the best model and its performance\n",
    "    if worst_mse_without_predictor < best_mse:\n",
    "        best_model = selected_predictors.copy()\n",
    "        best_mse = worst_mse_without_predictor\n",
    "\n",
    "# Now, fit the best model with all data\n",
    "X_best = X[best_model]\n",
    "model = LinearRegression()\n",
    "model.fit(X_best, y)\n",
    "\n",
    "# Compute the test MSE of the best model using LOOCV\n",
    "test_mse_best_model = []\n",
    "\n",
    "for train_index, test_index in loocv.split(X_best):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    test_mse_best_model.append(mse)\n",
    "\n",
    "# Compute the average test MSE for the best model\n",
    "average_test_mse_best_model = np.mean(test_mse_best_model)\n",
    "\n",
    "# Print the best model and its test MSE\n",
    "print(\"Best Backward Stepwise Model (Predictors):\", best_model)\n",
    "print(\"Test MSE of the Best Model:\", average_test_mse_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha for Ridge Regression: 10.0\n",
      "Test MSE of the Ridge Model: 1.7313156163921775\n"
     ]
    }
   ],
   "source": [
    "# Question 1e\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Initialize LOOCV\n",
    "loocv = LeaveOneOut()\n",
    "\n",
    "# Create a RidgeCV model with a range of alpha values\n",
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100]  # Adjust the range as needed\n",
    "ridge = RidgeCV(alphas=alphas, store_cv_values=True)\n",
    "\n",
    "# Initialize variables to store results\n",
    "best_alpha = None\n",
    "best_test_mse = float('inf')\n",
    "\n",
    "# Perform LOOCV to find the best alpha\n",
    "for train_index, test_index in loocv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Fit the RidgeCV model on the training data\n",
    "    ridge.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the optimal alpha value selected by RidgeCV\n",
    "    alpha = ridge.alpha_\n",
    "    \n",
    "    # Evaluate the model on the test data\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    # Update the best alpha and best test MSE if necessary\n",
    "    if mse < best_test_mse:\n",
    "        best_alpha = alpha\n",
    "        best_test_mse = mse\n",
    "\n",
    "# Fit the Ridge model with the best alpha on the entire dataset\n",
    "ridge.fit(X, y)\n",
    "\n",
    "# Compute the test MSE of the model\n",
    "test_mse_ridge = []\n",
    "\n",
    "for train_index, test_index in loocv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    test_mse_ridge.append(mse)\n",
    "\n",
    "# Compute the average test MSE for the Ridge model\n",
    "average_test_mse_ridge = np.mean(test_mse_ridge)\n",
    "\n",
    "# Print the best alpha and the test MSE of the Ridge model\n",
    "print(\"Best Alpha for Ridge Regression:\", best_alpha)\n",
    "print(\"Test MSE of the Ridge Model:\", average_test_mse_ridge)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha for Lasso Regression: 0.1\n",
      "Test MSE of the Lasso Model: 1.5866543012142005\n"
     ]
    }
   ],
   "source": [
    "# Question 1f\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Initialize LOOCV\n",
    "loocv = LeaveOneOut()\n",
    "\n",
    "# Create a LassoCV model with a range of alpha values\n",
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100]  # Adjust the range as needed\n",
    "lasso = LassoCV(alphas=alphas)\n",
    "\n",
    "# Initialize variables to store results\n",
    "best_alpha = None\n",
    "best_test_mse = float('inf')\n",
    "\n",
    "# Perform LOOCV to find the best alpha\n",
    "for train_index, test_index in loocv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Fit the LassoCV model on the training data\n",
    "    lasso.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the optimal alpha value selected by LassoCV\n",
    "    alpha = lasso.alpha_\n",
    "    \n",
    "    # Evaluate the model on the test data\n",
    "    y_pred = lasso.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    # Update the best alpha and best test MSE if necessary\n",
    "    if mse < best_test_mse:\n",
    "        best_alpha = alpha\n",
    "        best_test_mse = mse\n",
    "\n",
    "# Fit the Lasso model with the best alpha on the entire dataset\n",
    "# lasso = LassoCV(alpha=best_alpha)\n",
    "lasso.fit(X, y)\n",
    "\n",
    "# Compute the test MSE of the model\n",
    "test_mse_lasso = []\n",
    "\n",
    "for train_index, test_index in loocv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred = lasso.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    test_mse_lasso.append(mse)\n",
    "\n",
    "# Compute the average test MSE for the Lasso model\n",
    "average_test_mse_lasso = np.mean(test_mse_lasso)\n",
    "\n",
    "# Print the best alpha and the test MSE of the Lasso model\n",
    "print(\"Best Alpha for Lasso Regression:\", best_alpha)\n",
    "print(\"Test MSE of the Lasso Model:\", average_test_mse_lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Model  Test MSE\n",
      "0  Linear Regression (All Predictors)  1.796343\n",
      "1               Best Subset Selection  4.706194\n",
      "2          Forward Stepwise Selection  1.796343\n",
      "3    Ridge Regression (Optimal Alpha)  1.731316\n",
      "4    Lasso Regression (Optimal Alpha)  1.586654\n",
      "Best Model(s):\n",
      "                                Model  Test MSE\n",
      "4    Lasso Regression (Optimal Alpha)  1.586654\n",
      "3    Ridge Regression (Optimal Alpha)  1.731316\n",
      "2          Forward Stepwise Selection  1.796343\n",
      "0  Linear Regression (All Predictors)  1.796343\n",
      "1               Best Subset Selection  4.706194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annbi\\AppData\\Local\\Temp\\ipykernel_11088\\3214059107.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({'Model': 'Linear Regression (All Predictors)',\n",
      "C:\\Users\\annbi\\AppData\\Local\\Temp\\ipykernel_11088\\3214059107.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({'Model': 'Best Subset Selection',\n",
      "C:\\Users\\annbi\\AppData\\Local\\Temp\\ipykernel_11088\\3214059107.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({'Model': 'Forward Stepwise Selection',\n",
      "C:\\Users\\annbi\\AppData\\Local\\Temp\\ipykernel_11088\\3214059107.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({'Model': 'Ridge Regression (Optimal Alpha)',\n",
      "C:\\Users\\annbi\\AppData\\Local\\Temp\\ipykernel_11088\\3214059107.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({'Model': 'Lasso Regression (Optimal Alpha)',\n"
     ]
    }
   ],
   "source": [
    "# Question 1g\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = pd.DataFrame(columns=['Model', 'Test MSE'])\n",
    "\n",
    "# Add results for each model\n",
    "results = results.append({'Model': 'Linear Regression (All Predictors)', \n",
    "                          'Test MSE': average_test_mse_a}, ignore_index=True)\n",
    "\n",
    "results = results.append({'Model': 'Best Subset Selection',\n",
    "                          'Test MSE': average_test_mse_best_subset}, ignore_index=True)\n",
    "\n",
    "results = results.append({'Model': 'Forward Stepwise Selection', \n",
    "                          'Test MSE': average_test_mse_forward}, ignore_index=True)\n",
    "\n",
    "# results = results.append({'Model': 'Backward Stepwise Selection', \n",
    "#                           'Test MSE': average_test_mse_backward_stepwise}, ignore_index=True)\n",
    "\n",
    "results = results.append({'Model': 'Ridge Regression (Optimal Alpha)', \n",
    "                          'Test MSE': average_test_mse_ridge}, ignore_index=True)\n",
    "\n",
    "results = results.append({'Model': 'Lasso Regression (Optimal Alpha)',\n",
    "                          'Test MSE': average_test_mse_lasso}, ignore_index=True)\n",
    "\n",
    "# Print the table of results\n",
    "print(results)\n",
    "\n",
    "# To find the best model(s), you can sort the DataFrame by Test MSE in ascending order\n",
    "best_models = results.sort_values(by='Test MSE')\n",
    "\n",
    "# Print the best model(s)\n",
    "print(\"Best Model(s):\")\n",
    "print(best_models.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
